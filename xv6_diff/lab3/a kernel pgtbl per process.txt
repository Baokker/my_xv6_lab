diff --git a/kernel/defs.h b/kernel/defs.h
index e74b9fc..2fb5642 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -180,6 +180,12 @@ int             copyin(pagetable_t, char *, uint64, uint64);
 int             copyinstr(pagetable_t, char *, uint64, uint64);
 // add vmprint
 void            vmprint(pagetable_t pagetable);
+// add new function for kernel pg in each process
+void            kvmmap_with_certain_page(pagetable_t pg, uint64 va, uint64 pa, uint64 sz, int perm);
+void            kvmmap_with_certain_page(pagetable_t pg, uint64 va, uint64 pa, uint64 sz, int perm);
+pagetable_t     kvm_init_one();
+
+pte_t *         walk(pagetable_t pagetable, uint64 va, int alloc);
 
 // plic.c
 void            plicinit(void);
diff --git a/kernel/proc.c b/kernel/proc.c
index dab1e1d..5e33362 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -30,16 +30,6 @@ procinit(void)
   initlock(&pid_lock, "nextpid");
   for(p = proc; p < &proc[NPROC]; p++) {
       initlock(&p->lock, "proc");
-
-      // Allocate a page for the process's kernel stack.
-      // Map it high in memory, followed by an invalid
-      // guard page.
-      char *pa = kalloc();
-      if(pa == 0)
-        panic("kalloc");
-      uint64 va = KSTACK((int) (p - proc));
-      kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
-      p->kstack = va;
   }
   kvminithart();
 }
@@ -121,6 +111,26 @@ found:
     return 0;
   }
 
+  // add kernel page table
+  p->kernelpgtbl = kvm_init_one();
+  if (p->kernelpgtbl == 0){
+    freeproc(p);
+    release(&p->lock);
+    return 0;
+  }
+
+  // init in allocproc
+
+  // Allocate a page for the process's kernel stack.
+  // Map it high in memory, followed by an invalid
+  // guard page.
+  char *pa = kalloc();
+  if(pa == 0)
+    panic("kalloc");
+  uint64 va = KSTACK((int)(p - proc));
+  kvmmap_with_certain_page(p->kernelpgtbl, va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
+  p->kstack = va;
+
   // Set up new context to start executing at forkret,
   // which returns to user space.
   memset(&p->context, 0, sizeof(p->context));
@@ -130,6 +140,22 @@ found:
   return p;
 }
 
+// free pg recursively
+void kvm_free_pgtbl(pagetable_t pg){
+  for (int i = 0; i < 512; i++){
+    pte_t pte = pg[i];
+
+    // copy wrong!!
+    // if((pte & PTE_V) && (PTE_R|PTE_W|PTE_X) == 0){
+    if((pte & PTE_V) && (pte & (PTE_R|PTE_W|PTE_X)) == 0){
+      uint64 child = PTE2PA(pte);
+      kvm_free_pgtbl((pagetable_t)child);
+      pg[i] = 0;
+    } 
+  }
+  kfree((void*)pg);
+}
+
 // free a proc structure and the data hanging from it,
 // including user pages.
 // p->lock must be held.
@@ -139,9 +165,30 @@ freeproc(struct proc *p)
   if(p->trapframe)
     kfree((void*)p->trapframe);
   p->trapframe = 0;
+
+  // free kernel stack in process
+  // void *kstack_pa = (void*)kvmpa(p->kstack);
+  // kfree(kstack_pa);
+  // p->kstack = 0;
+
+  if (p->kstack){
+    pte_t* pte = walk(p->kernelpgtbl, p->kstack, 0);
+    if (pte == 0)
+      panic("freeproc: kstack");
+    kfree((void*)PTE2PA(*pte));
+  }
+  p->kstack = 0;
+
   if(p->pagetable)
     proc_freepagetable(p->pagetable, p->sz);
+
   p->pagetable = 0;
+  
+  if (p->kernelpgtbl){
+    kvm_free_pgtbl(p->kernelpgtbl);
+  }
+  p->kernelpgtbl = 0;
+  
   p->sz = 0;
   p->pid = 0;
   p->parent = 0;
@@ -473,8 +520,17 @@ scheduler(void)
         // before jumping back to us.
         p->state = RUNNING;
         c->proc = p;
+
+        // Switch to the independent kernel page table
+        w_satp(MAKE_SATP(p->kernelpgtbl));
+        // flush TLB
+        sfence_vma();
+
         swtch(&c->context, &p->context);
 
+        // Switch back to global kernel page table
+        kvminithart();
+
         // Process is done running for now.
         // It should have changed its p->state before coming back.
         c->proc = 0;
diff --git a/kernel/proc.h b/kernel/proc.h
index 9c16ea7..0b228d9 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -103,4 +103,6 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+
+  pagetable_t kernelpgtbl;     // add kernel page table
 };
diff --git a/kernel/virtio_disk.c b/kernel/virtio_disk.c
index 06e0645..50f2d91 100644
--- a/kernel/virtio_disk.c
+++ b/kernel/virtio_disk.c
@@ -17,6 +17,8 @@
 #include "buf.h"
 #include "virtio.h"
 
+#include "proc.h"
+
 // the address of virtio mmio register r.
 #define R(r) ((volatile uint32 *)(VIRTIO0 + (r)))
 
diff --git a/kernel/vm.c b/kernel/vm.c
index 764a8ca..6ca9cc9 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -6,6 +6,9 @@
 #include "defs.h"
 #include "fs.h"
 
+#include "spinlock.h"
+#include "proc.h"
+
 /*
  * the kernel's page table.
  */
@@ -16,35 +19,44 @@ extern char etext[];  // kernel.ld sets this to end of kernel code.
 extern char trampoline[]; // trampoline.S
 
 /*
- * create a direct-map page table for the kernel.
- */
-void
-kvminit()
-{
-  kernel_pagetable = (pagetable_t) kalloc();
-  memset(kernel_pagetable, 0, PGSIZE);
+* init a new kernel virtual map
+*/
+pagetable_t kvm_init_one(){
+  pagetable_t newpg = uvmcreate();
 
+  // copy but forget to modify the first argument. so sad
   // uart registers
-  kvmmap(UART0, UART0, PGSIZE, PTE_R | PTE_W);
+  kvmmap_with_certain_page(newpg, UART0, UART0, PGSIZE, PTE_R | PTE_W);
 
   // virtio mmio disk interface
-  kvmmap(VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);
+  kvmmap_with_certain_page(newpg, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);
 
   // CLINT
-  kvmmap(CLINT, CLINT, 0x10000, PTE_R | PTE_W);
+  kvmmap_with_certain_page(newpg, CLINT, CLINT, 0x10000, PTE_R | PTE_W);
 
   // PLIC
-  kvmmap(PLIC, PLIC, 0x400000, PTE_R | PTE_W);
+  kvmmap_with_certain_page(newpg, PLIC, PLIC, 0x400000, PTE_R | PTE_W);
 
   // map kernel text executable and read-only.
-  kvmmap(KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);
+  kvmmap_with_certain_page(newpg, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);
 
   // map kernel data and the physical RAM we'll make use of.
-  kvmmap((uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);
+  kvmmap_with_certain_page(newpg, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);
 
   // map the trampoline for trap entry/exit to
   // the highest virtual address in the kernel.
-  kvmmap(TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);
+  kvmmap_with_certain_page(newpg, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);
+
+  return newpg;
+}
+
+/*
+ * create a direct-map page table for the kernel.
+ */
+void
+kvminit()
+{
+  kernel_pagetable = kvm_init_one();
 }
 
 // Switch h/w page table register to the kernel's page table,
@@ -76,6 +88,7 @@ walk(pagetable_t pagetable, uint64 va, int alloc)
 
   for(int level = 2; level > 0; level--) {
     pte_t *pte = &pagetable[PX(level, va)];
+
     if(*pte & PTE_V) {
       pagetable = (pagetable_t)PTE2PA(*pte);
     } else {
@@ -85,6 +98,7 @@ walk(pagetable_t pagetable, uint64 va, int alloc)
       *pte = PA2PTE(pagetable) | PTE_V;
     }
   }
+  // printf("%d" ,(uint64)&pagetable[PX(0, va)]);
   return &pagetable[PX(0, va)];
 }
 
@@ -101,6 +115,7 @@ walkaddr(pagetable_t pagetable, uint64 va)
     return 0;
 
   pte = walk(pagetable, va, 0);
+
   if(pte == 0)
     return 0;
   if((*pte & PTE_V) == 0)
@@ -121,6 +136,13 @@ kvmmap(uint64 va, uint64 pa, uint64 sz, int perm)
     panic("kvmmap");
 }
 
+// simulate kvmmap
+void kvmmap_with_certain_page(pagetable_t pg, uint64 va, uint64 pa, uint64 sz, int perm)
+{
+  if(mappages(pg, va, sz, pa, perm) != 0)
+    panic("kvmmap with certain page");
+}
+
 // translate a kernel virtual address to
 // a physical address. only needed for
 // addresses on the stack.
@@ -132,11 +154,14 @@ kvmpa(uint64 va)
   pte_t *pte;
   uint64 pa;
   
-  pte = walk(kernel_pagetable, va, 0);
+  pte = walk(myproc()->kernelpgtbl, va, 0);
+  
   if(pte == 0)
     panic("kvmpa");
-  if((*pte & PTE_V) == 0)
+  if((*pte & PTE_V) == 0){
+    printf("%d\n",*pte);
     panic("kvmpa");
+  }
   pa = PTE2PA(*pte);
   return pa+off;
 }
@@ -154,8 +179,9 @@ mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)
   a = PGROUNDDOWN(va);
   last = PGROUNDDOWN(va + size - 1);
   for(;;){
-    if((pte = walk(pagetable, a, 1)) == 0)
+    if((pte = walk(pagetable, a, 1)) == 0){
       return -1;
+    }
     if(*pte & PTE_V)
       panic("remap");
     *pte = PA2PTE(pa) | perm | PTE_V;
@@ -180,8 +206,9 @@ uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)
     panic("uvmunmap: not aligned");
 
   for(a = va; a < va + npages*PGSIZE; a += PGSIZE){
-    if((pte = walk(pagetable, a, 0)) == 0)
+    if((pte = walk(pagetable, a, 0)) == 0){
       panic("uvmunmap: walk");
+    }
     if((*pte & PTE_V) == 0)
       panic("uvmunmap: not mapped");
     if(PTE_FLAGS(*pte) == PTE_V)
@@ -314,8 +341,9 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   char *mem;
 
   for(i = 0; i < sz; i += PGSIZE){
-    if((pte = walk(old, i, 0)) == 0)
+    if((pte = walk(old, i, 0)) == 0){
       panic("uvmcopy: pte should exist");
+    }
     if((*pte & PTE_V) == 0)
       panic("uvmcopy: page not present");
     pa = PTE2PA(*pte);
